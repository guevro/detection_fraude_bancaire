import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import (
    RandomForestClassifier,
    GradientBoostingClassifier,
    IsolationForest,
    BaggingClassifier
)
from sklearn.metrics import f1_score, classification_report, confusion_matrix
from imblearn.over_sampling import SMOTE
import warnings

# Ignorer les avertissements pour une meilleure lisibilit√© dans Streamlit
warnings.filterwarnings('ignore')

# --- Configuration de la page Streamlit ---
st.set_page_config(
    layout="wide",
    page_title="D√©tection de Fraude Bancaire  fraudbusters üõ°Ô∏è",
    initial_sidebar_state="expanded"
)

# --- Constantes du Projet ---
FILE_PATH = 'data_project.csv'
TARGET = 'FlagImpaye'
ID_COLUMNS = ['ZIBZIN', 'IDAvisAutorisationCheque', 'Heure']
DATE_COLUMN = 'DateTransaction'
SAMPLE_FRACTION = 0.30  # √âchantillonnage √† 30% des donn√©es

# --- 0. Fonctions de Chargement et de Pr√©paration ---

@st.cache_data(show_spinner="‚è≥ Chargement, √©chantillonnage et pr√©paration des donn√©es...")
def load_and_sample_data(file_path, sample_frac):
    """Charge le CSV, applique le formatage, et √©chantillonne."""
    try:
        df = pd.read_csv(
            file_path, sep=';', decimal=',', dayfirst=True, parse_dates=[DATE_COLUMN]
        )
    except Exception:
        df = pd.read_csv(file_path, sep=';', decimal=',', dayfirst=True)
        df[DATE_COLUMN] = pd.to_datetime(df[DATE_COLUMN], errors='coerce')

    df[TARGET] = df[TARGET].astype(int)

    # √âchantillonnage al√©atoire (30% des donn√©es)
    df_sampled = df.sample(frac=sample_frac, random_state=42).sort_values(by=DATE_COLUMN).reset_index(drop=True)
    
    # S√©paration temporelle (80% train, 20% test)
    split_index = int(0.8 * len(df_sampled))
    train_df = df_sampled.iloc[:split_index].copy()
    test_df = df_sampled.iloc[split_index:].copy()

    X_train_base = train_df.drop([TARGET] + ID_COLUMNS + [DATE_COLUMN], axis=1)
    y_train_base = train_df[TARGET]
    X_test_base = test_df.drop([TARGET] + ID_COLUMNS + [DATE_COLUMN], axis=1)
    y_test_base = test_df[TARGET]
    
    return X_train_base, y_train_base, X_test_base, y_test_base, df_sampled

# --- 1. Fonction de l'ensemble de la Pipeline ML ---

@st.cache_data(show_spinner="üöÄ Ex√©cution compl√®te de la Pipeline ML (I1, I2, Bagging)...")
def execute_ml_pipeline(X_train_base, y_train_base, X_test_base, y_test_base):
    """Ex√©cute les √©tapes de la pipeline ML."""
    
    numeric_features = X_train_base.columns.tolist()
    
    # 3. Pr√©traitement
    preprocessor = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='median')),
        ('scaler', StandardScaler())
    ])
    X_train_scaled = pd.DataFrame(preprocessor.fit_transform(X_train_base), columns=numeric_features, index=X_train_base.index)
    X_test_scaled = pd.DataFrame(preprocessor.transform(X_test_base), columns=numeric_features, index=X_test_base.index)
    
    # PARTIE 4 : Feature Engineering (IsolationForest)
    new_feature_name = 'Isolation_Anomaly_Score'
    X_train_no_fraud = X_train_scaled[y_train_base == 0]
    iforest = IsolationForest(contamination='auto', random_state=42, n_jobs=-1)
    iforest.fit(X_train_no_fraud)

    X_train_i2 = X_train_scaled.copy()
    X_test_i2 = X_test_scaled.copy()
    X_train_i2[new_feature_name] = -iforest.decision_function(X_train_i2)
    X_test_i2[new_feature_name] = -iforest.decision_function(X_test_i2)

    # 5. Gestion du d√©s√©quilibre (SMOTE)
    X_train_i1 = X_train_scaled 
    X_test_i1 = X_test_scaled.drop(new_feature_name, axis=1) 
    
    smote = SMOTE(random_state=42)
    X_train_smote_i1, y_train_smote_i1 = smote.fit_resample(X_train_i1, y_train_base)
    X_train_smote_i2, y_train_smote_i2 = smote.fit_resample(X_train_i2, y_train_base)
    
    
    # PARTIE 2 : Mod√©lisation et √âvaluation (I1 et I2)
    MODELS = {
        'LogisticRegression': LogisticRegression(solver='liblinear', random_state=42),
        'RandomForest': RandomForestClassifier(random_state=42, n_estimators=100, max_depth=10, n_jobs=-1),
        'GradientBoosting': GradientBoostingClassifier(random_state=42, n_estimators=100, max_depth=5),
        'CostSensitive_LogReg': LogisticRegression(solver='liblinear', random_state=42, class_weight='balanced'),
    }
    
    results = []
    param_grid = {'max_depth': [5, 10], 'n_estimators': [50, 100]}
    
    # IT√âRATION 1
    for name, model in MODELS.items():
        model.fit(X_train_smote_i1, y_train_smote_i1)
        f1 = f1_score(y_test_base, model.predict(X_test_i1))
        results.append({'Mod√®le': name, 'It√©ration': 'I1 (Baseline)', 'F1-Score': f1, 'ModelObject': model, 'X_test': X_test_i1})
        
    grid_search_i1 = GridSearchCV(RandomForestClassifier(random_state=42, n_jobs=-1), param_grid, scoring='f1', cv=3, n_jobs=-1)
    grid_search_i1.fit(X_train_smote_i1, y_train_smote_i1)
    f1_grid_i1 = f1_score(y_test_base, grid_search_i1.best_estimator_.predict(X_test_i1))
    results.append({'Mod√®le': 'GridSearch_RF', 'It√©ration': 'I1 (Baseline)', 'F1-Score': f1_grid_i1, 'ModelObject': grid_search_i1.best_estimator_, 'X_test': X_test_i1})


    # IT√âRATION 2
    for name, model in MODELS.items():
        model_clone = model.__class__(**model.get_params())
        model_clone.fit(X_train_smote_i2, y_train_smote_i2)
        f1 = f1_score(y_test_base, model_clone.predict(X_test_i2))
        results.append({'Mod√®le': name, 'It√©ration': 'I2 (+IF Score)', 'F1-Score': f1, 'ModelObject': model_clone, 'X_test': X_test_i2})

    grid_search_i2 = GridSearchCV(RandomForestClassifier(random_state=42, n_jobs=-1), param_grid, scoring='f1', cv=3, n_jobs=-1)
    grid_search_i2.fit(X_train_smote_i2, y_train_smote_i2)
    f1_grid_i2 = f1_score(y_test_base, grid_search_i2.best_estimator_.predict(X_test_i2))
    results.append({'Mod√®le': 'GridSearch_RF', 'It√©ration': 'I2 (+IF Score)', 'F1-Score': f1_grid_i2, 'ModelObject': grid_search_i2.best_estimator_, 'X_test': X_test_i2})
    
    results_df = pd.DataFrame(results)

    # PARTIE 3 : Post-traitement (Bagging)
    best_i2 = results_df[results_df['It√©ration'] == 'I2 (+IF Score)'].sort_values(by='F1-Score', ascending=False).iloc[0]
    base_estimator_i2 = best_i2['ModelObject']
    bagging_model = BaggingClassifier(estimator=base_estimator_i2, n_estimators=10, random_state=42, n_jobs=-1)

    bagging_model.fit(X_train_smote_i2, y_train_smote_i2)
    f1_bagging = f1_score(y_test_base, bagging_model.predict(X_test_i2))

    results.append({
        'Mod√®le': 'Bagging_Final', 'It√©ration': f"Post-traitement ({best_i2['Mod√®le']})",
        'F1-Score': f1_bagging, 'ModelObject': bagging_model, 'X_test': X_test_i2
    })
    
    final_results_df = pd.DataFrame(results)
    
    return final_results_df, y_test_base

# ==============================================================================
# STRUCTURE DE L'APPLICATION STREAMLIT
# ==============================================================================

st.title("üõ°Ô∏è Projet D√©tection de Fraude Bancaire par Machine Learning")
st.markdown("---")

# --- 1. CONFIGURATION et Chargement des Donn√©es ---
st.header("1. Configuration du Projet et Chargement des Donn√©es")
col1, col2, col3 = st.columns(3)

try:
    X_train_base, y_train_base, X_test_base, y_test_base, df_sampled = load_and_sample_data(FILE_PATH, SAMPLE_FRACTION)
    
    total_fraudes = y_train_base.sum() + y_test_base.sum()
    
    with col1:
        st.metric(label="Taille Totale de l'√âchantillon", value=f"{len(df_sampled):,} lignes")
    with col2:
        st.metric(label="Ratio d'√âchantillonnage", value=f"{SAMPLE_FRACTION*100:.0f}%")
    with col3:
        st.metric(label="Incidence de la Fraude", value=f"{total_fraudes / len(df_sampled) * 100:.3f}%", help="Classe positive (FlagImpaye=1) dans l'√©chantillon.")
    
    st.success("‚úÖ **Chargement r√©ussi.** Pipeline ML pr√™te √† √™tre ex√©cut√©e.")
    
    # Ex√©cuter la pipeline compl√®te
    results_df, y_test_base_final = execute_ml_pipeline(X_train_base, y_train_base, X_test_base, y_test_base)
    
except FileNotFoundError:
    st.error(f"‚ùå Erreur: Le fichier '{FILE_PATH}' n'a pas √©t√© trouv√©. Veuillez le placer dans le m√™me dossier.")
    st.stop()
except Exception as e:
    st.error(f"‚ùå Une erreur est survenue lors du chargement/traitement des donn√©es. Erreur: {e}")
    st.stop()


# --- 2. R√©sultats de Mod√©lisation (Tableau R√©capitulatif) ---

st.header("2. R√©sultats et Comparaison des Mod√®les")
st.markdown("### Tableau R√©capitulatif des F1-Scores")

# Calcul des am√©liorations par rapport √† la baseline (I1)
comparison_df = results_df.drop(columns=['ModelObject', 'X_test']).copy()
comparison_df['F1-Score sur Test'] = comparison_df['F1-Score'].round(4)
comparison_df = comparison_df.sort_values(by=['It√©ration', 'F1-Score'], ascending=[False, False]).reset_index(drop=True)

# Calculer Delta I2 vs I1 (Baseline)
baseline_scores = comparison_df[comparison_df['It√©ration'] == 'I1 (Baseline)'].set_index('Mod√®le')['F1-Score']
def calculate_improvement(row):
    if row['It√©ration'] == 'I2 (+IF Score)':
        baseline_score = baseline_scores.get(row['Mod√®le'])
        if baseline_score:
            delta = row['F1-Score'] - baseline_score
            perc = delta / baseline_score
            return f"{delta:.4f} ({perc*100:+.2f}%)"
    return 'N/A'

comparison_df['Am√©lioration vs I1 (Baseline)'] = comparison_df.apply(calculate_improvement, axis=1)

# Formatage final du tableau
comparison_df.drop(columns=['F1-Score'], inplace=True)
comparison_df.rename(columns={'Mod√®le': 'Mod√®le de Base'}, inplace=True)

st.dataframe(comparison_df.style.background_gradient(cmap=sns.light_palette("darkred", as_cmap=True), subset=['F1-Score sur Test']), use_container_width=True)

st.caption("Le score d'anomalie 'IF Score' a √©t√© ajout√© dans l'It√©ration 2.")

# --- Graphique de Comparaison ---

st.subheader("Visualisation de l'Impact de l'It√©ration 2")
df_plot = results_df.drop(columns=['ModelObject', 'X_test'])
df_plot['Mod√®le Complet'] = df_plot['Mod√®le'] + " (" + df_plot['It√©ration'].str.split(' ').str[0] + ")"
df_plot['F1-Score'] = df_plot['F1-Score'].round(4)

fig, ax = plt.subplots(figsize=(12, 6))
sns.barplot(data=df_plot, x='Mod√®le', y='F1-Score', hue='It√©ration', palette=['#1f77b4', '#ff7f0e'], ax=ax)
ax.set_title("Comparaison des F1-Scores par Mod√®le et It√©ration", fontsize=16)
ax.set_ylabel("F1-Score", fontsize=14)
ax.set_xlabel("Algorithme", fontsize=14)
plt.xticks(rotation=15)
st.pyplot(fig)


# --- 3. Synth√®se et Mod√®le Final ---
st.markdown("---")
st.header("3. Mod√®le Final et Analyse D√©taill√©e")

final_model_row = results_df.sort_values(by='F1-Score', ascending=False).iloc[0]
best_model_name = final_model_row['Mod√®le']
best_f1_score = final_model_row['F1-Score']
final_model_object = final_model_row['ModelObject']
X_test_final = final_model_row['X_test']

st.markdown(f"""
    Le **Mod√®le Final Retenu** est le **:trophy: {best_model_name}** (issu de l'it√©ration **{final_model_row['It√©ration']}**).
""")

col_metric, col_report, col_matrix = st.columns([1, 1.5, 2])

with col_metric:
    st.subheader("Performance Cl√©")
    st.metric(label="F1-Score Maximal Atteint", value=f"{best_f1_score:.4f}", delta=f"{best_f1_score-df_plot['F1-Score'].max():.4f}" if best_model_name == 'Bagging_Final' else None, delta_color="normal")
    
    st.info("Le F1-Score est la m√©trique la plus pertinente pour le d√©s√©quilibre de classes.")

with col_report:
    st.subheader("Rapport de Classification")
    y_pred_final = final_model_object.predict(X_test_final)
    report = classification_report(y_test_base_final, y_pred_final, output_dict=True)
    report_df = pd.DataFrame(report).transpose()
    st.dataframe(report_df[['precision', 'recall', 'f1-score', 'support']].style.format({'precision': "{:.3f}", 'recall': "{:.3f}", 'f1-score': "{:.3f}", 'support': "{:.0f}"}), use_container_width=True)

with col_matrix:
    st.subheader("Matrice de Confusion (Mod√®le Final)")
    cm = confusion_matrix(y_test_base_final, y_pred_final)
    fig_cm, ax_cm = plt.subplots(figsize=(5, 5))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Reds', cbar=False,
                xticklabels=['Non-Fraude (0)', 'Fraude (1)'],
                yticklabels=['Non-Fraude (0)', 'Fraude (1)'], ax=ax_cm)
    ax_cm.set_xlabel('Pr√©diction')
    ax_cm.set_ylabel('V√©rit√© Terrain')
    st.pyplot(fig_cm)
    
    st.markdown("""
        ‚ö†Ô∏è Les **Faux N√©gatifs (FN)** (fraudes manqu√©es) repr√©sentent le co√ªt le plus √©lev√©. Une augmentation du **Rappel (Recall)** est souhaitable.
    """)


# --- 4. Conclusion et Perspectives ---
st.markdown("---")
st.header("4. Conclusion et Pistes d'Am√©lioration")

st.markdown("""
### üí° Conclusion
Le travail sur l'√©chantillon de 30% a permis d'√©tablir une pipeline robuste. L'approche d'ensemble (Gradient Boosting ou Random Forest) s'est av√©r√©e la plus performante. L'int√©gration d'un signal d'anomalie non supervis√© (`Isolation_Anomaly_Score`) a valid√© l'id√©e que le *Feature Engineering* est essentiel pour cette probl√©matique.

### üî≠ Perspectives d'Am√©lioration
√âtant donn√© la difficult√© intrins√®que de la d√©tection de fraude sur des donn√©es r√©elles, les pistes suivantes sont sugg√©r√©es pour affiner la performance :
1.  **Optimisation Co√ªt-Sensible (XGBoost/LightGBM)** : Utiliser des mod√®les de *boosting* avanc√©s avec des **fonctions de co√ªt personnalis√©es** pour p√©naliser les Faux N√©gatifs bien plus lourdement que les Faux Positifs.
2.  **Autoencodeurs** : Explorer l'utilisation des **Autoencodeurs Variationnels (VAE)** pour g√©n√©rer un score d'anomalie plus sophistiqu√© que l'Isolation Forest, en exploitant la puissance du Deep Learning pour mod√©liser le comportement normal (Non-Fraude).
3.  **Sur√©chantillonnage Cibl√©e** : Remplacer le SMOTE par **ADASYN**, qui g√©n√®re des √©chantillons synth√©tiques pr√©f√©rentiellement pour les instances minoritaires les plus difficiles √† classer, permettant de mieux d√©finir la fronti√®re de d√©cision.
""")